{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 克安 playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from customloss import CustomLoss\n",
    "\n",
    "\n",
    "class Trainer(object):\n",
    "    def __init__(self, model, train_dataloader,  helper=None): # no test set for HW2-2\n",
    "\n",
    "        self.train_loader = train_dataloader\n",
    "\n",
    "        # Use cuda if available\n",
    "        self.__CUDA__ = torch.cuda.is_available()\n",
    "\n",
    "        if self.__CUDA__:\n",
    "            self.model = model.cuda()\n",
    "        else:\n",
    "            self.model = model.cpu()\n",
    "\n",
    "        self.parameters = model.parameters()\n",
    "        self.loss_fn = CustomLoss()\n",
    "        self.loss = None\n",
    "        self.optimizer = optim.Adam(self.parameters, lr=3e-4) # TODO: change optimizer\n",
    "\n",
    "        # used for printing model output\n",
    "        self.helper = helper\n",
    "\n",
    "\n",
    "    def train(self, epoch, check_result=False): # TODO: currently using epoch as steps\n",
    "        self.model.train()\n",
    "\n",
    "        test_input, test_truth = None, None\n",
    "\n",
    "        for batch_idx, batch in enumerate(self.train_loader):\n",
    "            # prepare data\n",
    "            a = time.time()\n",
    "            padded_prev_sentences, padded_curr_sentences, lengths_curr_sentences = batch\n",
    "            if self.__CUDA__:\n",
    "                padded_prev_sentences, padded_curr_sentences = padded_prev_sentences.cuda(), padded_curr_sentences.cuda()\n",
    "\n",
    "            padded_prev_sentences, padded_curr_sentences = Variable(padded_prev_sentences), Variable(padded_curr_sentences)\n",
    "\n",
    "            # start training process\n",
    "            self.optimizer.zero_grad()\n",
    "            seq_Prob, seq_predictions = self.model(prev_sentences=padded_prev_sentences, mode='train', curr_sentences=padded_curr_sentences, steps=epoch)\n",
    "            padded_curr_sentences = padded_curr_sentences[:, 1:]  # eliminate <SOS>\n",
    "\n",
    "            if check_result:\n",
    "                if test_input is None or test_truth is None:\n",
    "                    test_input = padded_prev_sentences[:3]\n",
    "                    test_truth = padded_curr_sentences[:3]\n",
    "\n",
    "\n",
    "            loss = self.loss_fn(seq_Prob, padded_curr_sentences, lengths_curr_sentences)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # print out training info\n",
    "            if (batch_idx+1):\n",
    "                info = self.get_training_info(\n",
    "                    epoch=epoch,\n",
    "                    batch_id=batch_idx,\n",
    "                    batch_size=len(lengths_curr_sentences),\n",
    "                    total_data_size=len(self.train_loader.dataset),\n",
    "                    n_batch=len(self.train_loader),\n",
    "                    loss=loss.data[0]\n",
    "                )\n",
    "                print('\\r', info, '   ', int(time.time()-a), 'seconds/batch', end='') # original: end='\\r'\n",
    "        print()\n",
    "\n",
    "\n",
    "        if check_result:\n",
    "            _, test_predictions = self.model(prev_sentences=padded_prev_sentences, mode='train', curr_sentences=padded_curr_sentences, steps=epoch)\n",
    "            result = [' '.join(self.helper.index2sentence(s)) for s in test_predictions]\n",
    "            print('Training Result: \\n{} \\n{}\\n{}\\n'.format(result[0], result[1], result[2]))\n",
    "            truth = [' '.join(self.helper.index2sentence(s)) for s in test_truth]\n",
    "            print('Ground Truth: \\n{} \\n{}\\n{}\\n'.format(truth[0], truth[1], truth[2]))\n",
    "\n",
    "\n",
    "\n",
    "    def eval(self, check_result=False):\n",
    "        # set model to evaluation(testing) mode\n",
    "        self.model.eval()\n",
    "\n",
    "        test_predictions, test_truth = None, None\n",
    "\n",
    "        for batch_idx, batch in enumerate(self.train_loader):\n",
    "            # prepare data\n",
    "            padded_prev_sentences, padded_curr_sentences, lengths_curr_sentences = batch\n",
    "            if self.__CUDA__:\n",
    "                padded_prev_sentences, padded_curr_sentences = padded_prev_sentences.cuda(), padded_curr_sentences.cuda()\n",
    "\n",
    "            padded_prev_sentences, padded_curr_sentences = Variable(padded_prev_sentences), Variable(padded_curr_sentences)\n",
    "\n",
    "\n",
    "            # start inferencing process\n",
    "            seq_Prob, seq_predictions = self.model(padded_prev_sentences, mode='inference')\n",
    "            padded_curr_sentences = padded_curr_sentences[:, 1:]  # eliminate <SOS>\n",
    "\n",
    "            test_predictions = seq_predictions[:3]\n",
    "            test_truth = padded_curr_sentences[:3]\n",
    "\n",
    "            break\n",
    "\n",
    "        if check_result:\n",
    "            result = [' '.join(self.helper.index2sentence(s)) for s in test_predictions]\n",
    "            print('Testing Result: \\n{} \\n{}\\n{}\\n'.format(result[0], result[1], result[2]))\n",
    "            truth = [' '.join(self.helper.index2sentence(s)) for s in test_truth]\n",
    "            print('Ground Truth: \\n{} \\n{}\\n{}\\n'.format(truth[0], truth[1], truth[2]))\n",
    "\n",
    "            #logger.info('Testing loss: {}'.format(loss))\n",
    "\n",
    "    #@log_method(logger)\n",
    "    def get_training_info(self,**kwargs):\n",
    "        ep = kwargs.pop(\"epoch\", None)\n",
    "        bID = kwargs.pop(\"batch_id\", None)\n",
    "        bs = kwargs.pop(\"batch_size\", None)\n",
    "        tds = kwargs.pop(\"total_data_size\", None)\n",
    "        nb = kwargs.pop(\"n_batch\", None)\n",
    "        loss = kwargs.pop(\"loss\", None)\n",
    "        info = \"Training Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(ep, (bID+1)*bs, tds, 100.*bID/nb, loss)\n",
    "        return info\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initalizing vocabulary...\n",
      "Building mapping...\n",
      "Parsing training data to Dataset()...\n",
      "Finished creating Dataset() !\n",
      "Start training...\n",
      " Training Epoch: 1 [66/2729578 (0%)]\tLoss: 6.604533     2 seconds/batch"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-69:\n",
      "Process Process-67:\n",
      "Process Process-70:\n",
      "Process Process-68:\n",
      "Process Process-66:\n",
      "Process Process-71:\n",
      "Process Process-72:\n",
      "Process Process-65:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b5bda8922776>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Start training...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-4c146571bada>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epoch, check_result)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_Prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_curr_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths_curr_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    import os\n",
    "    import time\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    from torch.autograd import Variable\n",
    "    from torch.utils.data import DataLoader\n",
    "    from vocabulary import Vocabulary\n",
    "    from dataset import TrainingDataset, collate_fn\n",
    "    from model import VideoCaptionGenerator, EncoderRNN, DecoderRNN\n",
    "    from customloss import CustomLoss\n",
    "\n",
    "    training_data_path='data/clr_conversation.txt'\n",
    "    helper = Vocabulary(training_data_path)\n",
    "    \n",
    "    dataset = TrainingDataset(training_data_path, helper)\n",
    "    dataloader = DataLoader(dataset, batch_size=3, shuffle=True, num_workers=8, collate_fn=collate_fn)\n",
    "    # original batch_size=128\n",
    "    \n",
    "    EPOCH = 300\n",
    "    MDL_OUTDIR = 'model'\n",
    "    if not os.path.exists(MDL_OUTDIR):\n",
    "        os.mkdir(MDL_OUTDIR)\n",
    "\n",
    "    encoder = EncoderRNN(word_vec_filepath='word_vectors.npy', hidden_size=1024, num_layers=1)\n",
    "    decoder = DecoderRNN(word_vec_filepath='word_vectors.npy', hidden_size=1024, num_layers=1)\n",
    "    model = VideoCaptionGenerator(encoder=encoder, decoder=decoder)\n",
    "\n",
    "    trainer = Trainer(model=model, train_dataloader=dataloader, helper=helper)\n",
    "\n",
    "    s = time.time()\n",
    "    print('Start training...')\n",
    "    for epoch in range(EPOCH):\n",
    "        trainer.train(epoch+1, check_result=True)\n",
    "        trainer.eval(check_result=True)\n",
    "\n",
    "    e = time.time()\n",
    "\n",
    "    torch.save(model, \"{}/{}.h5\".format(MDL_OUTDIR, 'test'))\n",
    "\n",
    "    logger.info(\"Finished training {}  Time elapsed: {: .3f} seconds. \\n\".format('test', e-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
