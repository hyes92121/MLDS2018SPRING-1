{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('Pong-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, scipy, scipy.misc\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing image stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro(I,image_size=[80,80]):\n",
    "    \"\"\"    \n",
    "    Input: \n",
    "    RGB image: np.array\n",
    "        RGB screen of game, shape: (210, 160, 3)\n",
    "    Default return: np.array \n",
    "        Grayscale image, shape: (80, 80, 1)\n",
    "    \n",
    "    \"\"\"\n",
    "    I = I[35:195]\n",
    "    I = I[::2, ::2, 0]\n",
    "    I[I == 144] = 0\n",
    "    I[I == 109] = 0\n",
    "    I[I != 0 ] = 1\n",
    "    return I.astype(np.float)\n",
    "    # return I.astype(np.float).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(I):\n",
    "    plt.gray()\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(I, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = env.reset()\n",
    "I_old = I.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_old = I.copy()\n",
    "for i in range(5):\n",
    "    I, _, _, _ = env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for thing in (prepro(I) - prepro(I_old)):\n",
    "    if thing in [1,-1]:\n",
    "        print(thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(prepro(I) - prepro(I_old))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = torch.nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3) # (batch_size, 16, 208, 158)\n",
    "conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3) # (batch_size, 32, 206, 156)\n",
    "fc1 = torch.nn.Linear(32 * 76 * 76, 64)\n",
    "fc2 = torch.nn.Linear(64, 32)\n",
    "fc3 = torch.nn.Linear(32, 3) # 6 actions to choose from, only taking 3 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(torch.nn.Module):\n",
    "    def __init__(self, gamma=0.99, lr=1e-4, rmsprop_decay=0.99):\n",
    "        super(Policy, self).__init__()\n",
    "\n",
    "#         self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3) # (batch_size, 16, 208, 158)\n",
    "#         self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3) # (batch_size, 32, 206, 156)\n",
    "#         self.fc1 = torch.nn.Linear(32 * 76 * 76, 64)\n",
    "#         self.fc2 = torch.nn.Linear(64, 32)\n",
    "#         self.fc3 = torch.nn.Linear(32, 3) # 6 actions to choose from, only taking 3 here\n",
    "#         # known actions: 0(no move), 2(up), 3(down)\n",
    "\n",
    "        self.fc4 = torch.nn.Linear(80*80, 256)\n",
    "        self.fc5 = torch.nn.Linear(256, 256)\n",
    "        self.fc6 = torch.nn.Linear(256, 3)\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.lr = lr\n",
    "        self.rmsprop_decay = rmsprop_decay\n",
    "        self.random_action_episodes = 0\n",
    "        \n",
    "        self.output2action = {0: 0, 1: 2, 2: 3}\n",
    "        self.saved_log_probs = []\n",
    "        self.rewards = []\n",
    "        \n",
    "    def forward(self, x): # x: np.array (1, 80, 80)\n",
    "\n",
    "        x = Variable(torch.Tensor(x))\n",
    "        if torch.cuda.is_available():\n",
    "             x = x.cuda()\n",
    "        x = x.view(-1, 80*80)\n",
    "        x = self.fc4(x) # TODO: add batch norm?\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.fc5(x)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.fc6(x)\n",
    "\n",
    "\n",
    "        action_probs = torch.nn.functional.softmax(x, dim=1)\n",
    "        return action_probs # (batch_size, 6)\n",
    "\n",
    "    def reset(self):\n",
    "        self.saved_log_probs = []\n",
    "        self.rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = Policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-1.1680e-02  6.4054e-03 -6.8477e-03  ...   6.1079e-03 -7.7141e-04 -1.0044e-02\n",
       "-6.8361e-03  4.1599e-03 -3.1595e-05  ...   8.4786e-03  4.3608e-03 -1.0854e-02\n",
       "-4.2969e-03  6.0781e-03 -8.1219e-03  ...  -1.2140e-02  2.4697e-03  4.5803e-03\n",
       "                ...                   ⋱                   ...                \n",
       " 9.7562e-03  1.6991e-03 -1.1516e-02  ...   1.2231e-02 -1.0155e-02 -7.4317e-03\n",
       "-3.2122e-03 -7.0174e-03 -7.9087e-03  ...  -5.9183e-03 -5.6066e-03  1.1751e-02\n",
       "-5.3492e-03 -1.1511e-02  2.9818e-03  ...   6.0135e-03 -2.9464e-03  8.7818e-03\n",
       "[torch.FloatTensor of size 256x6400]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.state_dict()['fc4.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-205-13f0e060ec14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fc4.weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "policy.named_parameters()['fc4.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      " 3.1583e-03 -2.6997e-02  3.0856e-02  ...   2.0772e-02 -3.2540e-02 -1.8699e-02\n",
      "-3.9914e-02 -3.2156e-02 -3.5675e-03  ...   5.8396e-02  2.1690e-02 -9.8056e-03\n",
      " 3.0208e-02 -1.8891e-02  6.0833e-02  ...  -2.6416e-02  5.5039e-02  4.5472e-02\n",
      "                ...                   ⋱                   ...                \n",
      " 3.1977e-02  1.9102e-02  4.9685e-02  ...  -8.4944e-03 -5.4329e-02  1.5440e-02\n",
      " 4.2826e-02 -3.2541e-02 -5.9553e-02  ...   2.7837e-02  3.7150e-02 -5.2498e-02\n",
      " 2.9265e-02  7.7444e-03 -3.7267e-02  ...  -3.1599e-02 -2.9033e-02  5.6836e-02\n",
      "[torch.FloatTensor of size 256x256]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, param in enumerate(policy.parameters()):\n",
    "    if idx == 2:\n",
    "        print(param)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for param in policy.parameters():\n",
    "    print(param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4fd5410833e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# print('[Time step {}] Finished step, about to backprop'.format(t))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mpolicy_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# NOTE: only tried this with batch_size=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                                             \u001b[0;31m#if batch_size > 1, not sure if we need to manually average gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "policy = Policy()\n",
    "policy.train()\n",
    "optimizer = torch.optim.Adam(policy.parameters())\n",
    "for i_episode in range(20):\n",
    "    observation = env.reset()\n",
    "    optimizer.zero_grad()\n",
    "    policy.episode_reward = 0\n",
    "     \n",
    "    for t in range(100):\n",
    "        # self.env.env.render()\n",
    "        policy_output = policy(observation) # (batch_size, 6)\n",
    "        action = int(torch.max(policy_output, dim=1)[1].data) # torch.max returns (max val, argmax)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        policy.episode_reward += reward\n",
    "        # print('[Time step {}] Finished step, about to backprop'.format(t))\n",
    "        policy_output[:,action].backward(retain_graph=False) # NOTE: only tried this with batch_size=1\n",
    "                                            #if batch_size > 1, not sure if we need to manually average gradients\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "    if not done:\n",
    "        print('Force terminated episode after running for 100 steps')\n",
    "    print('[After {} seconds] Reward is {}'.format(time.time()-a, policy.episode_reward))\n",
    "    \n",
    "    for param in policy.parameters():\n",
    "        param.grad *= policy.episode_reward\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = torch.nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3)\n",
    "conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n",
    "fc1 = torch.nn.Linear(206 * 156 * 32, 512)\n",
    "fc2 = torch.nn.Linear(512,6)\n",
    "logsoftmax = torch.nn.LogSoftmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-20bff870d3f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m210\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "img = Variable(torch.Tensor(a.reshape(1,3,210,160)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 208, 158])\n",
      "torch.Size([1, 32, 206, 156])\n"
     ]
    }
   ],
   "source": [
    "x = conv1(img)\n",
    "print(x.shape)\n",
    "y = conv2(x)\n",
    "print(y.shape)\n",
    "y = y.view(-1, 32*206*156)\n",
    "z = fc1(y)\n",
    "z = fc2(z)\n",
    "output = logsoftmax(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "  8.2107   4.8800  -6.4096  -6.6704  13.4930   6.7540\n",
       "[torch.FloatTensor of size 1x6]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = int(torch.max(z, dim=1)[1].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[:,action].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'hey': 0, 'wow': 1}\n",
    "with open('read.json', 'w') as outfile:\n",
    "    json.dump(data, outfile, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
