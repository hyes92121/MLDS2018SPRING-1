{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('Pong-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, scipy, scipy.misc\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing image stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro(I,image_size=[80,80]):\n",
    "    \"\"\"    \n",
    "    Input: \n",
    "    RGB image: np.array\n",
    "        RGB screen of game, shape: (210, 160, 3)\n",
    "    Default return: np.array \n",
    "        Grayscale image, shape: (80, 80, 1)\n",
    "    \n",
    "    \"\"\"\n",
    "    I = I[35:195]\n",
    "    I = I[::2, ::2, 0]\n",
    "    I[I == 144] = 0\n",
    "    I[I == 109] = 0\n",
    "    I[I != 0 ] = 1\n",
    "    return I.astype(np.float)\n",
    "    # return I.astype(np.float).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(I):\n",
    "    plt.gray()\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(I, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = env.reset()\n",
    "I_old = I.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_old = I.copy()\n",
    "for i in range(1):\n",
    "    I, _, _, _ = env.step(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for thing in (prepro(I) - prepro(I_old)):\n",
    "    if thing in [1,-1]:\n",
    "        print(thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(prepro(I) - prepro(I_old))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(torch.nn.Module):\n",
    "    def __init__(self, gamma=0.99, lr=1e-4, rmsprop_decay=0.99):\n",
    "        super(Policy, self).__init__()\n",
    "\n",
    "#         self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3) # (batch_size, 16, 208, 158)\n",
    "#         self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3) # (batch_size, 32, 206, 156)\n",
    "#         self.fc1 = torch.nn.Linear(32 * 76 * 76, 64)\n",
    "#         self.fc2 = torch.nn.Linear(64, 32)\n",
    "#         self.fc3 = torch.nn.Linear(32, 3) # 6 actions to choose from, only taking 3 here\n",
    "#         # known actions: 0(no move), 2(up), 3(down)\n",
    "\n",
    "        self.fc4 = torch.nn.Linear(80*80, 256)\n",
    "        self.fc5 = torch.nn.Linear(256, 256)\n",
    "        self.fc6 = torch.nn.Linear(256, 3)\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.lr = lr\n",
    "        self.rmsprop_decay = rmsprop_decay\n",
    "        self.random_action_episodes = 0\n",
    "        \n",
    "        self.output2action = {0: 0, 1: 2, 2: 3}\n",
    "        self.saved_log_probs = []\n",
    "        self.rewards = []\n",
    "        \n",
    "    def forward(self, x): # x: np.array (1, 80, 80)\n",
    "\n",
    "        x = Variable(torch.Tensor(x))\n",
    "        if torch.cuda.is_available():\n",
    "             x = x.cuda()\n",
    "        x = x.view(-1, 80*80)\n",
    "        x = self.fc4(x) # TODO: add batch norm?\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.fc5(x)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.fc6(x)\n",
    "\n",
    "\n",
    "        action_probs = torch.nn.functional.softmax(x, dim=1)\n",
    "        return action_probs # (batch_size, 6)\n",
    "\n",
    "    def reset(self):\n",
    "        self.saved_log_probs = []\n",
    "        self.rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = Policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-1.1680e-02  6.4054e-03 -6.8477e-03  ...   6.1079e-03 -7.7141e-04 -1.0044e-02\n",
       "-6.8361e-03  4.1599e-03 -3.1595e-05  ...   8.4786e-03  4.3608e-03 -1.0854e-02\n",
       "-4.2969e-03  6.0781e-03 -8.1219e-03  ...  -1.2140e-02  2.4697e-03  4.5803e-03\n",
       "                ...                   ⋱                   ...                \n",
       " 9.7562e-03  1.6991e-03 -1.1516e-02  ...   1.2231e-02 -1.0155e-02 -7.4317e-03\n",
       "-3.2122e-03 -7.0174e-03 -7.9087e-03  ...  -5.9183e-03 -5.6066e-03  1.1751e-02\n",
       "-5.3492e-03 -1.1511e-02  2.9818e-03  ...   6.0135e-03 -2.9464e-03  8.7818e-03\n",
       "[torch.FloatTensor of size 256x6400]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.state_dict()['fc4.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-205-13f0e060ec14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fc4.weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "policy.named_parameters()['fc4.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      " 3.1583e-03 -2.6997e-02  3.0856e-02  ...   2.0772e-02 -3.2540e-02 -1.8699e-02\n",
      "-3.9914e-02 -3.2156e-02 -3.5675e-03  ...   5.8396e-02  2.1690e-02 -9.8056e-03\n",
      " 3.0208e-02 -1.8891e-02  6.0833e-02  ...  -2.6416e-02  5.5039e-02  4.5472e-02\n",
      "                ...                   ⋱                   ...                \n",
      " 3.1977e-02  1.9102e-02  4.9685e-02  ...  -8.4944e-03 -5.4329e-02  1.5440e-02\n",
      " 4.2826e-02 -3.2541e-02 -5.9553e-02  ...   2.7837e-02  3.7150e-02 -5.2498e-02\n",
      " 2.9265e-02  7.7444e-03 -3.7267e-02  ...  -3.1599e-02 -2.9033e-02  5.6836e-02\n",
      "[torch.FloatTensor of size 256x256]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, param in enumerate(policy.parameters()):\n",
    "    if idx == 2:\n",
    "        print(param)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for param in policy.parameters():\n",
    "    print(param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4fd5410833e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# print('[Time step {}] Finished step, about to backprop'.format(t))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mpolicy_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# NOTE: only tried this with batch_size=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                                             \u001b[0;31m#if batch_size > 1, not sure if we need to manually average gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "policy = Policy()\n",
    "policy.train()\n",
    "optimizer = torch.optim.Adam(policy.parameters())\n",
    "for i_episode in range(20):\n",
    "    observation = env.reset()\n",
    "    optimizer.zero_grad()\n",
    "    policy.episode_reward = 0\n",
    "     \n",
    "    for t in range(100):\n",
    "        # self.env.env.render()\n",
    "        policy_output = policy(observation) # (batch_size, 6)\n",
    "        action = int(torch.max(policy_output, dim=1)[1].data) # torch.max returns (max val, argmax)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        policy.episode_reward += reward\n",
    "        # print('[Time step {}] Finished step, about to backprop'.format(t))\n",
    "        policy_output[:,action].backward(retain_graph=False) # NOTE: only tried this with batch_size=1\n",
    "                                            #if batch_size > 1, not sure if we need to manually average gradients\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "    if not done:\n",
    "        print('Force terminated episode after running for 100 steps')\n",
    "    print('[After {} seconds] Reward is {}'.format(time.time()-a, policy.episode_reward))\n",
    "    \n",
    "    for param in policy.parameters():\n",
    "        param.grad *= policy.episode_reward\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = torch.nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3)\n",
    "conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n",
    "fc1 = torch.nn.Linear(206 * 156 * 32, 512)\n",
    "fc2 = torch.nn.Linear(512,6)\n",
    "logsoftmax = torch.nn.LogSoftmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-20bff870d3f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m210\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "img = Variable(torch.Tensor(a.reshape(1,3,210,160)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 208, 158])\n",
      "torch.Size([1, 32, 206, 156])\n"
     ]
    }
   ],
   "source": [
    "x = conv1(img)\n",
    "print(x.shape)\n",
    "y = conv2(x)\n",
    "print(y.shape)\n",
    "y = y.view(-1, 32*206*156)\n",
    "z = fc1(y)\n",
    "z = fc2(z)\n",
    "output = logsoftmax(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "  8.2107   4.8800  -6.4096  -6.6704  13.4930   6.7540\n",
       "[torch.FloatTensor of size 1x6]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = int(torch.max(z, dim=1)[1].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[:,action].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'hey': 0, 'wow': 1}\n",
    "with open('read.json', 'w') as outfile:\n",
    "    json.dump(data, outfile, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
