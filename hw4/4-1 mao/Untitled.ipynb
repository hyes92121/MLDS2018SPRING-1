{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('Pong-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, scipy, scipy.misc\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing image stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro(o,image_size=[80,80]):\n",
    "    \"\"\"    \n",
    "    Input: \n",
    "    RGB image: np.array\n",
    "        RGB screen of game, shape: (210, 160, 3)\n",
    "    Default return: np.array \n",
    "        Grayscale image, shape: (80, 80, 1)\n",
    "    \n",
    "    \"\"\"\n",
    "    y = o.astype(np.uint8)\n",
    "    resized = scipy.misc.imresize(y, image_size) # (80,80,3)\n",
    "    # return np.expand_dims(resized.astype(np.float32),axis=2)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 80)\n",
      "(1, 80, 80)\n"
     ]
    }
   ],
   "source": [
    "data = 0.2126 * data[:, :, 0] + 0.7152 * data[:, :, 1] + 0.0722 * data[:, :, 2]\n",
    "resized = cv2.resize(data, dsize=(80, 80), interpolation=cv2.INTER_CUBIC)\n",
    "print(resized.shape)\n",
    "resized = np.expand_dims(resized,axis=0)\n",
    "print(resized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 80, 1)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    data, _, _, _ = env.step(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATUAAAEyCAYAAACbGke8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAEKNJREFUeJzt3W+MXXWdx/H3p62DbAXbKjuZULKwsYFg3LbaIERjFMSga4AHhoBm02ya9Im7gaxRy26yick+0JioPNiYNKL2gUUQZdsQo3YrZrObTWX4owIVW1kIJf0jSIOLClvnuw/uoQ6TTufOn3tv/fF+JZM559xzc770Tt8959wZJlWFJLVi2agHkKSlZNQkNcWoSWqKUZPUFKMmqSlGTVJTjJqkpiwqakmuSfJ4koNJti3VUJK0UFnoN98mWQ78ArgaOATcD9xUVY8t3XiSND8rFvHcy4CDVfUEQJJvAtcBs0Zt9erVNTExsYhDSnqt2r9//7NVdd5c+y0maucDT09bPwS883RPmJiYYOfOnYs4pKTXqo0bNz7Vz34Df6MgydYkk0kmjx8/PujDSXqNW8yZ2jPABdPW13bbXqWqtgPbAd72trfVOeecs4hDStLpLeZM7X5gXZKLkowBNwK7l2YsSVqYBZ+pVdWJJH8HfB9YDny1qh5dsskkaQEWc/lJVX0X+O4SzSJJi7bg71NbiLGxsRofHx/a8SS149ChQw9U1aa59vPHpCQ1xahJaopRk9QUoyapKUZNUlOMmqSmGDVJTTFqkppi1CQ1xahJaopRk9QUoyapKUZNUlOMmqSmGDVJTTFqkppi1CQ1xahJaopRk9QUoyapKUZNUlOMmqSmGDVJTTFqkpoyZ9SSfDXJsSSPTNu2JsmeJAe6z6sHO6Yk9aefM7WvA9fM2LYN2FtV64C93bokjdyKuXaoqv9IcuGMzdcB7+2WdwA/Aj69hHMtyEsvvXRy+aMf/eis++3cufPk8llnnTXQmQbt17/+9cnlF1988VWPrVy58uTymjVrhjaTNEoLvac2XlWHu+UjwPgSzSNJizLnmdpcqqqS1GyPJ9kKbAVYvnz5Yg8nSae10KgdTTJRVYeTTADHZtuxqrYD2wHGxsZmjd9SSHJy+eWXX+5rvz910/9bqmrWx6TXioVefu4GNnfLm4FdSzOOJC1OP9/ScQfw38DFSQ4l2QJ8Frg6yQHg/d26JI1cP+9+3jTLQ1ct8SyStGiLfqNAozX9WzVWrVo162Mz77dJrfLHpCQ1xahJaoqXn3/ipl9WnnvuubM+Jr1WeKYmqSlGTVJTjJqkphg1SU0xapKaYtQkNcWoSWqKUZPUFKMmqSlGTVJTjJqkphg1SU0xapKa0tT/pWNsbOzk8p49e/raT1JbPFOT1BSjJqkpTV1+Tvf73/9+1CNIGgHP1CQ1xahJaopRk9QUoyapKXNGLckFSe5L8liSR5Pc3G1fk2RPkgPd59WDH1eSTq+fM7UTwCeq6lLgcuDjSS4FtgF7q2odsLdbl6SRmjNqVXW4qh7sln8D7AfOB64DdnS77QCuH9SQktSved1TS3IhsBHYB4xX1eHuoSPA+JJOJkkL0HfUkrwB+DZwS1W9MP2x6v0q8FP+OvAkW5NMJpmcmppa1LCSNJe+opbkdfSC9o2q+k63+WiSie7xCeDYqZ5bVduralNVbVq2zDdbJQ1WP+9+Brgd2F9VX5j20G5gc7e8Gdi19ONJ0vz087Of7wL+BvhZkoe7bf8IfBa4K8kW4CnghsGMKEn9mzNqVfWfQGZ5+KqlHUeSFsebXJKaYtQkNcWoSWqKUZPUFKMmqSlGTVJTjJqkphg1SU0xapKaYtQkNcWoSWqKUZPUFKMmqSlGTVJTjJqkphg1SU0xapKaYtQkNcWoSWqKUZPUFKMmqSlGTVJTjJqkphg1SU0xapKaMmfUkrw+yY+T/CTJo0k+022/KMm+JAeT3JlkbPDjStLp9XOm9hJwZVWtBzYA1yS5HPgc8MWqegvwPLBlcGNKUn/mjFr1/G+3+rruo4Argbu77TuA6wcyoSTNQ1/31JIsT/IwcAzYA/wSOF5VJ7pdDgHnD2ZESepfX1Grqj9U1QZgLXAZcEm/B0iyNclkksmpqakFjilJ/ZnXu59VdRy4D7gCWJVkRffQWuCZWZ6zvao2VdWmZct8s1XSYPXz7ud5SVZ1y2cDVwP76cXtI91um4FdgxpSkvq1Yu5dmAB2JFlOL4J3VdW9SR4DvpnkX4CHgNsHOKck9WXOqFXVT4GNp9j+BL37a5J0xvAml6SmGDVJTTFqkppi1CQ1xahJaopRk9QUoyapKUZNUlOMmqSmGDVJTTFqkppi1CQ1xahJaopRk9QUoyapKUZNUlOMmqSmGDVJTTFqkppi1CQ1xahJaopRk9QUoyapKUZNUlOMmqSm9B21JMuTPJTk3m79oiT7khxMcmeSscGNKUn9mc+Z2s3A/mnrnwO+WFVvAZ4HtizlYJK0EH1FLcla4K+Br3TrAa4E7u522QFcP4gBJWk++j1T+xLwKWCqW38TcLyqTnTrh4Dzl3g2SZq3OaOW5MPAsap6YCEHSLI1yWSSyampqbmfIEmLsKKPfd4FXJvkQ8DrgXOB24BVSVZ0Z2trgWdO9eSq2g5sBxgbG6slmVqSZjHnmVpV3VpVa6vqQuBG4IdV9THgPuAj3W6bgV0Dm1KS+rSY71P7NPAPSQ7Su8d2+9KMJEkL18/l50lV9SPgR93yE8BlSz+SJC2cP1EgqSlGTVJTjJqkphg1SU0xapKaYtQkNcWoSWqKUZPUFKMmqSlGTVJTjJqkphg1SU0xapKaYtQkNcWoSWqKUZPUFKMmqSlGTVJTjJqkphg1SU0xapKaYtQkNcWoSWqKUZPUFKMmqSl9/Yb2JE8CvwH+AJyoqk1J1gB3AhcCTwI3VNXzgxlTkvoznzO191XVhqra1K1vA/ZW1Tpgb7cuSSO1mMvP64Ad3fIO4PrFjyNJi9Nv1Ar4QZIHkmztto1X1eFu+QgwvuTTSdI89XVPDXh3VT2T5M+BPUl+Pv3BqqokdaondhHcCrB8+fJFDStJc+nrTK2qnuk+HwPuAS4DjiaZAOg+H5vluduralNVbVq2zDdbJQ3WnJVJsjLJOa8sAx8AHgF2A5u73TYDuwY1pCT1q5/Lz3HgniSv7L+zqr6X5H7griRbgKeAGwY3piT1Z86oVdUTwPpTbH8OuGoQQ0nSQnmTS1JTjJqkphg1SU0xapKaYtQkNcWoSWqKUZPUFKMmqSlGTVJTjJqkphg1SU0xapKaYtQkNcWoSWqKUZPUFKMmqSlGTVJTjJqkphg1SU0xapKaYtQkNcWoSWqKUZPUFKMmqSlGTVJT+opaklVJ7k7y8yT7k1yRZE2SPUkOdJ9XD3pYSZpLv2dqtwHfq6pLgPXAfmAbsLeq1gF7u3VJGqk5o5bkjcB7gNsBqurlqjoOXAfs6HbbAVw/qCElqV/9nKldBPwK+FqSh5J8JclKYLyqDnf7HAHGBzWkJPWrn6itAN4OfLmqNgIvMuNSs6oKqFM9OcnWJJNJJqemphY7rySdVj9ROwQcqqp93frd9CJ3NMkEQPf52KmeXFXbq2pTVW1atsw3WyUN1pyVqaojwNNJLu42XQU8BuwGNnfbNgO7BjKhJM3Dij73+3vgG0nGgCeAv6UXxLuSbAGeAm4YzIiS1L++olZVDwObTvHQVUs7jiQtjje5JDXFqElqilGT1BSjJqkpRk1SU4yapKYYNUlNMWqSmmLUJDXFqElqilGT1BSjJqkpRk1SU4yapKYYNUlNMWqSmmLUJDXFqElqilGT1BSjJqkpRk1SU4yapKYYNUlNMWqSmmLUJDVlzqgluTjJw9M+XkhyS5I1SfYkOdB9Xj2MgSXpdOaMWlU9XlUbqmoD8A7gt8A9wDZgb1WtA/Z265I0UvO9/LwK+GVVPQVcB+zotu8Arl/KwSSdGapq1o8z0XyjdiNwR7c8XlWHu+UjwPiSTSVJC9R31JKMAdcC35r5WPWSfcpsJ9maZDLJ5NTU1IIHlaR+rJjHvh8EHqyqo9360SQTVXU4yQRw7FRPqqrtwHaAsbGxM/N8VdKr/O53vzu5/MlPfnLW/T7/+c+fXD777LMHOlO/5nP5eRN/vPQE2A1s7pY3A7uWaihJWqi+opZkJXA18J1pmz8LXJ3kAPD+bl2SRqqvy8+qehF404xtz9F7N1SSzhjzuae2aCdOnOC5554b5iElLcD0e2rPPvvsrPtN//v8p3hPTZLOeEZNUlMyzO8Kfutb31p33HHH3DtKOmOcrhFJhjbH+vXrH6iqTXPt55mapKYYNUlNMWqSmjLUb+moKvz5T6kdZ+L/qcMzNUlNMWqSmmLUJDXFqElqilGT1BSjJqkpRk1SU4yapKYYNUlNMWqSmmLUJDXFqElqilGT1BSjJqkpRk1SU4yapKYYNUlNMWqSmmLUJDVlqL/3M8mvgKeANwOz/y774TgTZgDnmMk5Xs05/ugvquq8uXYaatROHjSZ7OeXkrY+g3M4h3MsPS8/JTXFqElqyqiitn1Ex53uTJgBnGMm53g155inkdxTk6RB8fJTUlOMmqSmDDVqSa5J8niSg0m2DfG4X01yLMkj07atSbInyYHu8+ohzHFBkvuSPJbk0SQ3j2KWJK9P8uMkP+nm+Ey3/aIk+7rX584kY4OcY9o8y5M8lOTeUc2R5MkkP0vycJLJbtsovkZWJbk7yc+T7E9yxQi+Pi7u/hxe+XghyS2j+PNYiKFFLcly4F+BDwKXAjcluXRIh/86cM2MbduAvVW1DtjbrQ/aCeATVXUpcDnw8e7PYNizvARcWVXrgQ3ANUkuBz4HfLGq3gI8D2wZ8ByvuBnYP219VHO8r6o2TPt+rFF8jdwGfK+qLgHW0/tzGeocVfV49+ewAXgH8FvgnmHPsWBVNZQP4Arg+9PWbwVuHeLxLwQembb+ODDRLU8Ajw9rlmkz7AKuHuUswJ8BDwLvpPcd4ytO9XoN8Phr6f0FuRK4F8iI5ngSePOMbUN9XYA3Av9D9wbeqOaYcewPAP816jnm8zHMy8/zgaenrR/qto3KeFUd7paPAOPDPHiSC4GNwL5RzNJd8j0MHAP2AL8EjlfViW6XYb0+XwI+BUx1628a0RwF/CDJA0m2dtuG/bpcBPwK+Fp3Of6VJCtHMMd0NwJ3dMsj/TvTL98oAKr3T8/QvrclyRuAbwO3VNULo5ilqv5QvcuLtcBlwCWDPuZMST4MHKuqB4Z97FN4d1W9nd7tkY8nec/0B4f0uqwA3g58uao2Ai8y4xJvmF+r3b3Ma4FvzXxs2H9n5mOYUXsGuGDa+tpu26gcTTIB0H0+NoyDJnkdvaB9o6q+M8pZAKrqOHAfvcu8VUlWdA8N4/V5F3BtkieBb9K7BL1tBHNQVc90n4/Ru390GcN/XQ4Bh6pqX7d+N73Ijerr44PAg1V1tFsf2dfpfAwzavcD67p3tsbondbuHuLxZ9oNbO6WN9O7vzVQSQLcDuyvqi+MapYk5yVZ1S2fTe++3n56cfvIsOaoqluram1VXUjv6+GHVfWxYc+RZGWSc15Zpncf6RGG/LpU1RHg6SQXd5uuAh4b9hzT3MQfLz0Z4RzzM8wbeMCHgF/Qu3/zT0M87h3AYeD/6P1ruIXevZu9wAHg34E1Q5jj3fRO2X8KPNx9fGjYswB/BTzUzfEI8M/d9r8EfgwcpHfJcdYQX6P3AveOYo7ueD/pPh595WtzRF8jG4DJ7rX5N2D1iOZYCTwHvHHatqHPsZAPf0xKUlN8o0BSU4yapKYYNUlNMWqSmmLUJDXFqElqilGT1JT/B8SFVQyOzsWdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data = env.reset()\n",
    "# data = prepro(data)\n",
    "data = 0.2126 * data[:, :, 0] + 0.7152 * data[:, :, 1] + 0.0722 * data[:, :, 2]\n",
    "data = data[30:,:]\n",
    "resized = cv2.resize(data, dsize=(80, 80), interpolation=cv2.INTER_CUBIC)\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(resized, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = torch.nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3)\n",
    "conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Variable(torch.Tensor(np.expand_dims(resized,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 78, 78])\n",
      "torch.Size([1, 32, 76, 76])\n"
     ]
    }
   ],
   "source": [
    "x = conv1(img)\n",
    "print(x.shape)\n",
    "y = conv2(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3) # (batch_size, 16, 208, 158)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3) # (batch_size, 32, 206, 156)\n",
    "        self.fc1 = torch.nn.Linear(206 * 156 * 32, 256)\n",
    "        self.fc2 = torch.nn.Linear(256, 6) # 6 actions to choose from\n",
    "        self.logsoftmax = torch.nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        self.episode_reward = 0\n",
    "        \n",
    "    def forward(self, x): # x: np.array (batch_size, 210, 160, 3)\n",
    "        x = x.reshape(-1,3,210,160) # (batch_size, 3, 210, 160) Conv2d needs channel dim in front\n",
    "        x = Variable(torch.Tensor(x))\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(-1, 32*206*156)\n",
    "        x = self.fc1(x) # TODO: add batch norm?\n",
    "        x = self.fc2(x)\n",
    "        output = self.logsoftmax(x) # this is log(p), need to take derivative of this wrt params\n",
    "        return output # (batch_size, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4fd5410833e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# print('[Time step {}] Finished step, about to backprop'.format(t))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mpolicy_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# NOTE: only tried this with batch_size=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                                             \u001b[0;31m#if batch_size > 1, not sure if we need to manually average gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "policy = Policy()\n",
    "policy.train()\n",
    "optimizer = torch.optim.Adam(policy.parameters())\n",
    "for i_episode in range(20):\n",
    "    observation = env.reset()\n",
    "    optimizer.zero_grad()\n",
    "    policy.episode_reward = 0\n",
    "     \n",
    "    for t in range(100):\n",
    "        # self.env.env.render()\n",
    "        policy_output = policy(observation) # (batch_size, 6)\n",
    "        action = int(torch.max(policy_output, dim=1)[1].data) # torch.max returns (max val, argmax)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        policy.episode_reward += reward\n",
    "        # print('[Time step {}] Finished step, about to backprop'.format(t))\n",
    "        policy_output[:,action].backward(retain_graph=False) # NOTE: only tried this with batch_size=1\n",
    "                                            #if batch_size > 1, not sure if we need to manually average gradients\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "    if not done:\n",
    "        print('Force terminated episode after running for 100 steps')\n",
    "    print('[After {} seconds] Reward is {}'.format(time.time()-a, policy.episode_reward))\n",
    "    \n",
    "    for param in policy.parameters():\n",
    "        param.grad *= policy.episode_reward\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = torch.nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3)\n",
    "conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n",
    "fc1 = torch.nn.Linear(206 * 156 * 32, 512)\n",
    "fc2 = torch.nn.Linear(512,6)\n",
    "logsoftmax = torch.nn.LogSoftmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Variable(torch.Tensor(a.reshape(1,3,210,160)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 208, 158])\n",
      "torch.Size([1, 32, 206, 156])\n"
     ]
    }
   ],
   "source": [
    "x = conv1(img)\n",
    "print(x.shape)\n",
    "y = conv2(x)\n",
    "print(y.shape)\n",
    "y = y.view(-1, 32*206*156)\n",
    "z = fc1(y)\n",
    "z = fc2(z)\n",
    "output = logsoftmax(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "  8.2107   4.8800  -6.4096  -6.6704  13.4930   6.7540\n",
       "[torch.FloatTensor of size 1x6]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = int(torch.max(z, dim=1)[1].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[:,action].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 7 \n",
       "-21.8379   5.7717  -5.9310  19.1889   8.3340  33.8346   2.1224  19.7966\n",
       "\n",
       "Columns 8 to 15 \n",
       " 14.3258 -46.1118  16.0139   5.6273 -13.8274   5.9326   1.6676 -19.8407\n",
       "\n",
       "Columns 16 to 23 \n",
       "-27.6719 -39.0822  13.9200 -22.0696  -6.5525  13.1250 -28.6126 -10.2397\n",
       "\n",
       "Columns 24 to 31 \n",
       " 11.4150  13.4097  28.4361 -31.5592  -4.2237 -55.0887  16.1179 -29.0268\n",
       "\n",
       "Columns 32 to 39 \n",
       "-35.1181  25.2986   5.6320 -11.1191   2.6955   4.3656  -8.6665   3.8037\n",
       "\n",
       "Columns 40 to 47 \n",
       " 17.0454  63.1836  31.0468 -13.9832 -18.1233  14.8643  -0.6245  31.2789\n",
       "\n",
       "Columns 48 to 55 \n",
       " 18.5735  -3.0820  -4.7338  -3.9332  -9.8126   2.6434 -31.5285  -2.9424\n",
       "\n",
       "Columns 56 to 63 \n",
       "  0.5116   5.0216 -25.2562  19.2960  28.7456   1.1983  -2.7695 -13.7059\n",
       "\n",
       "Columns 64 to 71 \n",
       " -9.3781  -9.7354  26.3769  -4.5851 -22.7312  19.2095 -29.6818  10.2846\n",
       "\n",
       "Columns 72 to 79 \n",
       " -0.3456 -36.2800  31.0172  -1.2440  -4.8356 -20.5486 -11.0203  42.2295\n",
       "\n",
       "Columns 80 to 87 \n",
       "  1.2154 -38.9901 -12.1746   1.3580   5.1829   6.4726  25.7143  -4.4766\n",
       "\n",
       "Columns 88 to 95 \n",
       " 14.6171   1.3111   6.0969  17.5528 -17.7841  -4.7666 -31.6356 -36.2767\n",
       "\n",
       "Columns 96 to 103 \n",
       "-11.0935  15.1032  21.4149 -22.2433  -4.1817  -0.4403 -16.3690 -43.2826\n",
       "\n",
       "Columns 104 to 111 \n",
       " 24.6872   4.4954  55.7610   5.4027   2.8121  36.4014  10.4636  41.9384\n",
       "\n",
       "Columns 112 to 119 \n",
       "-29.3760 -16.7669  -1.2046 -24.1810  21.3440  -4.2366  24.9977  -1.8475\n",
       "\n",
       "Columns 120 to 127 \n",
       " 24.3021  -2.1985  23.8711  19.6132  42.5774  19.1287 -16.8360  -9.5132\n",
       "\n",
       "Columns 128 to 135 \n",
       " 17.0857 -59.5120  -2.3565  18.1578  14.3178 -29.6559  -5.2859  25.8380\n",
       "\n",
       "Columns 136 to 143 \n",
       " -4.8067  22.2749  -0.7378 -51.4838  -6.8618   3.9384  -1.3369 -45.6294\n",
       "\n",
       "Columns 144 to 151 \n",
       "  3.6874   3.2537  28.5879  22.3508  -3.9138 -32.1245  31.2391 -30.3112\n",
       "\n",
       "Columns 152 to 159 \n",
       "-25.3999  -8.6151   7.9007   3.8354 -21.7197   9.6578  -1.5294  21.7409\n",
       "\n",
       "Columns 160 to 167 \n",
       "-15.8527  -2.1220   3.9893   4.7563  24.3246  -2.2164 -29.1444 -42.5794\n",
       "\n",
       "Columns 168 to 175 \n",
       " 41.1878 -13.9113  15.1048  19.2417 -16.8404  12.5235 -21.3986  36.2530\n",
       "\n",
       "Columns 176 to 183 \n",
       " -0.4510  -0.1441   2.8001  -4.3994  19.0501  19.8952 -27.7130 -29.8499\n",
       "\n",
       "Columns 184 to 191 \n",
       "-25.7164  22.8156   2.7524  11.0292 -14.8024  34.7023 -41.7795  -7.1346\n",
       "\n",
       "Columns 192 to 199 \n",
       "-38.7009  51.4863   1.0393 -11.4073  36.8512  18.6443 -17.3431  21.7456\n",
       "\n",
       "Columns 200 to 207 \n",
       " -1.6827 -16.4096   1.5150  -6.0931  31.5611  -7.4332  -9.0421  27.8185\n",
       "\n",
       "Columns 208 to 215 \n",
       "-19.1519  17.2748 -25.0704 -45.6974  30.3378   9.6069  28.9177  17.1683\n",
       "\n",
       "Columns 216 to 223 \n",
       "-19.8738 -21.0376  35.8932 -16.9770  48.0531  -2.1324 -32.1467  39.4611\n",
       "\n",
       "Columns 224 to 231 \n",
       " -7.2708  17.0282  40.7257  -7.0320  35.8300 -15.5154 -26.6360 -46.5864\n",
       "\n",
       "Columns 232 to 239 \n",
       " 33.9000 -18.9250  -3.9224  -7.9037  -5.9689  -1.9260   4.1021  23.1245\n",
       "\n",
       "Columns 240 to 247 \n",
       "  7.4367  -8.5410  12.3225  22.7690 -16.7972  16.8655  27.6436   2.3052\n",
       "\n",
       "Columns 248 to 255 \n",
       "-37.1584  -9.4626 -12.1752  11.9206   3.3934  27.5783  10.6134 -11.9761\n",
       "\n",
       "Columns 256 to 263 \n",
       " 20.8837  10.0496  21.5256   7.4903  -2.1556 -15.7330  15.4345  28.1666\n",
       "\n",
       "Columns 264 to 271 \n",
       "  6.8218 -23.6158 -57.3730  -5.7122  28.8973 -23.1002 -16.0469 -16.2827\n",
       "\n",
       "Columns 272 to 279 \n",
       "  5.9582  20.6354  11.3413  14.8228  33.4883  -9.5791 -18.3495  -8.4786\n",
       "\n",
       "Columns 280 to 287 \n",
       " -1.5284   3.7855  -9.4308  14.7992  10.9988   3.2433  -7.7535  20.2706\n",
       "\n",
       "Columns 288 to 295 \n",
       "-11.8345  12.8744 -33.9258  -9.2870   4.3151   5.5390  15.2273 -25.7334\n",
       "\n",
       "Columns 296 to 303 \n",
       " 12.8324  19.5718 -25.0834   0.2940  35.5392  14.6281 -17.6539 -10.9388\n",
       "\n",
       "Columns 304 to 311 \n",
       " 47.3659  -4.8735  21.3902  -7.4284   4.4460  29.7763  37.5620 -21.4271\n",
       "\n",
       "Columns 312 to 319 \n",
       " 21.7020  -7.8194  16.9926  15.6487 -18.0342   9.8141 -18.7319  14.5715\n",
       "\n",
       "Columns 320 to 327 \n",
       "  8.6727 -22.1139  52.1951  13.3487 -11.4028  -2.0886  34.6042  -3.4942\n",
       "\n",
       "Columns 328 to 335 \n",
       " 20.9045   4.6647   0.0747  17.6911  16.1236 -13.4522   0.9493  10.6132\n",
       "\n",
       "Columns 336 to 343 \n",
       " 36.5903  -2.0259  10.8561  37.5319  20.0509  18.0379 -11.2698  13.9050\n",
       "\n",
       "Columns 344 to 351 \n",
       "  9.7649 -13.0603  11.0124 -43.5259 -38.6690   9.6962  -0.4295  -1.9523\n",
       "\n",
       "Columns 352 to 359 \n",
       " 27.8497  16.5657  43.3615  -5.3380   0.8719   2.0013   1.8835 -38.8319\n",
       "\n",
       "Columns 360 to 367 \n",
       " 21.9228 -25.3589 -13.0837 -37.0152 -21.6216  -3.3380 -12.8716 -24.1913\n",
       "\n",
       "Columns 368 to 375 \n",
       "  7.6197  18.4455  -4.0572 -14.5150  19.3340  24.5548  18.4174 -20.3507\n",
       "\n",
       "Columns 376 to 383 \n",
       "  6.2959   9.4159 -12.2776   2.6038  31.3451 -10.5363 -28.0442 -28.0523\n",
       "\n",
       "Columns 384 to 391 \n",
       "-10.5722 -39.2377   7.0534 -14.4470 -10.4322  -6.8406  31.7884  46.2006\n",
       "\n",
       "Columns 392 to 399 \n",
       " -1.3867  12.2301 -23.5396   5.4450 -25.0549  48.2387 -19.1450 -10.4639\n",
       "\n",
       "Columns 400 to 407 \n",
       "  0.7409  36.3038 -31.6036  18.5425 -48.3819  11.5905 -40.5025  28.7086\n",
       "\n",
       "Columns 408 to 415 \n",
       " -0.6948   2.0838 -10.3261 -16.4382  12.3250 -15.7093  -0.5021 -13.5335\n",
       "\n",
       "Columns 416 to 423 \n",
       " 24.1892 -18.7432 -20.6409   2.8416  -5.0076  29.9666  21.1412 -39.4818\n",
       "\n",
       "Columns 424 to 431 \n",
       "  4.0866 -17.4198  -8.6416  10.1667  17.7103 -52.3843   1.6171  -5.7740\n",
       "\n",
       "Columns 432 to 439 \n",
       " 10.7370  13.9547  -2.0203  35.4564  -2.0768 -12.1122  12.3126  -7.8704\n",
       "\n",
       "Columns 440 to 447 \n",
       "  1.3855  -9.8722  -9.9758 -24.4545  -6.7601   7.4614   4.0031  39.0072\n",
       "\n",
       "Columns 448 to 455 \n",
       " -1.1802 -30.2551   8.1268 -47.0823   8.1306  13.4628   6.3641   3.0420\n",
       "\n",
       "Columns 456 to 463 \n",
       " 29.3240  14.8081 -31.4584   9.3968 -40.0453  18.7227 -14.2872 -16.9459\n",
       "\n",
       "Columns 464 to 471 \n",
       "  4.0603  18.7489   2.0369  -6.1700 -11.6406   9.9792   3.0809  12.9343\n",
       "\n",
       "Columns 472 to 479 \n",
       " 29.7556  -8.6942  17.4200  22.0931  19.9657   5.9007  -4.5967  20.4422\n",
       "\n",
       "Columns 480 to 487 \n",
       " -7.9340 -41.1238   4.0871 -16.4710  -4.5741  27.9164   6.4173   4.7509\n",
       "\n",
       "Columns 488 to 495 \n",
       " -5.3607  32.5552 -20.5474 -25.2837 -13.8846  -2.5189   5.8106  10.8990\n",
       "\n",
       "Columns 496 to 503 \n",
       "-15.4077 -30.1200  13.1649 -22.0402   8.1255   0.5419  -6.7744 -10.0476\n",
       "\n",
       "Columns 504 to 511 \n",
       " 29.4092 -14.5876  -3.9823  15.0414  -3.2787  -8.5620 -16.2069  -3.6625\n",
       "[torch.FloatTensor of size 1x512]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
