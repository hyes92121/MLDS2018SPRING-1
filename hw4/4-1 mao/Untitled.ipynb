{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('Pong-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, scipy, scipy.misc\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing image stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro(I,image_size=[80,80]):\n",
    "    \"\"\"    \n",
    "    Input: \n",
    "    RGB image: np.array\n",
    "        RGB screen of game, shape: (210, 160, 3)\n",
    "    Default return: np.array \n",
    "        Grayscale image, shape: (80, 80, 1)\n",
    "    \n",
    "    \"\"\"\n",
    "    I = I[35:195]\n",
    "    I = I[::2, ::2, 0]\n",
    "    I[I == 144] = 0\n",
    "    I[I == 109] = 0\n",
    "    I[I != 0 ] = 1\n",
    "    # return I.astype(np.float).ravel()\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(I):\n",
    "    plt.gray()\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(I, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    I, _, _, _ = env.step(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(prepro(I))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(torch.nn.Module):\n",
    "    def __init__(self, gamma=0.99, lr=1e-4, rmsprop_decay=0.99):\n",
    "        super(Policy, self).__init__()\n",
    "\n",
    "#         self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3) # (batch_size, 16, 208, 158)\n",
    "#         self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3) # (batch_size, 32, 206, 156)\n",
    "#         self.fc1 = torch.nn.Linear(32 * 76 * 76, 64)\n",
    "#         self.fc2 = torch.nn.Linear(64, 32)\n",
    "#         self.fc3 = torch.nn.Linear(32, 3) # 6 actions to choose from, only taking 3 here\n",
    "#         # known actions: 0(no move), 2(up), 3(down)\n",
    "\n",
    "        self.fc4 = torch.nn.Linear(80*80, 256)\n",
    "        self.fc5 = torch.nn.Linear(256, 256)\n",
    "        self.fc6 = torch.nn.Linear(256, 3)\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.lr = lr\n",
    "        self.rmsprop_decay = rmsprop_decay\n",
    "        self.random_action_episodes = 0\n",
    "        \n",
    "        self.output2action = {0: 0, 1: 2, 2: 3}\n",
    "        self.saved_log_probs = []\n",
    "        self.rewards = []\n",
    "        \n",
    "    def forward(self, x): # x: np.array (1, 80, 80)\n",
    "\n",
    "        x = Variable(torch.Tensor(x))\n",
    "        if torch.cuda.is_available():\n",
    "             x = x.cuda()\n",
    "        x = x.view(-1, 80*80)\n",
    "        x = self.fc4(x) # TODO: add batch norm?\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.fc5(x)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.fc6(x)\n",
    "\n",
    "\n",
    "        action_probs = torch.nn.functional.softmax(x, dim=1)\n",
    "        return action_probs # (batch_size, 6)\n",
    "\n",
    "    def reset(self):\n",
    "        self.saved_log_probs = []\n",
    "        self.rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = Policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-1.1680e-02  6.4054e-03 -6.8477e-03  ...   6.1079e-03 -7.7141e-04 -1.0044e-02\n",
       "-6.8361e-03  4.1599e-03 -3.1595e-05  ...   8.4786e-03  4.3608e-03 -1.0854e-02\n",
       "-4.2969e-03  6.0781e-03 -8.1219e-03  ...  -1.2140e-02  2.4697e-03  4.5803e-03\n",
       "                ...                   ⋱                   ...                \n",
       " 9.7562e-03  1.6991e-03 -1.1516e-02  ...   1.2231e-02 -1.0155e-02 -7.4317e-03\n",
       "-3.2122e-03 -7.0174e-03 -7.9087e-03  ...  -5.9183e-03 -5.6066e-03  1.1751e-02\n",
       "-5.3492e-03 -1.1511e-02  2.9818e-03  ...   6.0135e-03 -2.9464e-03  8.7818e-03\n",
       "[torch.FloatTensor of size 256x6400]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.state_dict()['fc4.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-205-13f0e060ec14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fc4.weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "policy.named_parameters()['fc4.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      " 3.1583e-03 -2.6997e-02  3.0856e-02  ...   2.0772e-02 -3.2540e-02 -1.8699e-02\n",
      "-3.9914e-02 -3.2156e-02 -3.5675e-03  ...   5.8396e-02  2.1690e-02 -9.8056e-03\n",
      " 3.0208e-02 -1.8891e-02  6.0833e-02  ...  -2.6416e-02  5.5039e-02  4.5472e-02\n",
      "                ...                   ⋱                   ...                \n",
      " 3.1977e-02  1.9102e-02  4.9685e-02  ...  -8.4944e-03 -5.4329e-02  1.5440e-02\n",
      " 4.2826e-02 -3.2541e-02 -5.9553e-02  ...   2.7837e-02  3.7150e-02 -5.2498e-02\n",
      " 2.9265e-02  7.7444e-03 -3.7267e-02  ...  -3.1599e-02 -2.9033e-02  5.6836e-02\n",
      "[torch.FloatTensor of size 256x256]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, param in enumerate(policy.parameters()):\n",
    "    if idx == 2:\n",
    "        print(param)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for param in policy.parameters():\n",
    "    print(param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4fd5410833e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# print('[Time step {}] Finished step, about to backprop'.format(t))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mpolicy_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# NOTE: only tried this with batch_size=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                                             \u001b[0;31m#if batch_size > 1, not sure if we need to manually average gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "policy = Policy()\n",
    "policy.train()\n",
    "optimizer = torch.optim.Adam(policy.parameters())\n",
    "for i_episode in range(20):\n",
    "    observation = env.reset()\n",
    "    optimizer.zero_grad()\n",
    "    policy.episode_reward = 0\n",
    "     \n",
    "    for t in range(100):\n",
    "        # self.env.env.render()\n",
    "        policy_output = policy(observation) # (batch_size, 6)\n",
    "        action = int(torch.max(policy_output, dim=1)[1].data) # torch.max returns (max val, argmax)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        policy.episode_reward += reward\n",
    "        # print('[Time step {}] Finished step, about to backprop'.format(t))\n",
    "        policy_output[:,action].backward(retain_graph=False) # NOTE: only tried this with batch_size=1\n",
    "                                            #if batch_size > 1, not sure if we need to manually average gradients\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "    if not done:\n",
    "        print('Force terminated episode after running for 100 steps')\n",
    "    print('[After {} seconds] Reward is {}'.format(time.time()-a, policy.episode_reward))\n",
    "    \n",
    "    for param in policy.parameters():\n",
    "        param.grad *= policy.episode_reward\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = torch.nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3)\n",
    "conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n",
    "fc1 = torch.nn.Linear(206 * 156 * 32, 512)\n",
    "fc2 = torch.nn.Linear(512,6)\n",
    "logsoftmax = torch.nn.LogSoftmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-20bff870d3f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m210\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "img = Variable(torch.Tensor(a.reshape(1,3,210,160)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 208, 158])\n",
      "torch.Size([1, 32, 206, 156])\n"
     ]
    }
   ],
   "source": [
    "x = conv1(img)\n",
    "print(x.shape)\n",
    "y = conv2(x)\n",
    "print(y.shape)\n",
    "y = y.view(-1, 32*206*156)\n",
    "z = fc1(y)\n",
    "z = fc2(z)\n",
    "output = logsoftmax(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "  8.2107   4.8800  -6.4096  -6.6704  13.4930   6.7540\n",
       "[torch.FloatTensor of size 1x6]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = int(torch.max(z, dim=1)[1].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[:,action].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'hey': 0, 'wow': 1}\n",
    "with open('read.json', 'w') as outfile:\n",
    "    json.dump(data, outfile, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
