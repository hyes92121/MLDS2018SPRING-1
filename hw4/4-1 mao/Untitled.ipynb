{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('Pong-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, scipy, scipy.misc\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing image stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro(o,image_size=[80,80]):\n",
    "    \"\"\"    \n",
    "    Input: \n",
    "    RGB image: np.array\n",
    "        RGB screen of game, shape: (210, 160, 3)\n",
    "    Default return: np.array \n",
    "        Grayscale image, shape: (80, 80, 1)\n",
    "    \n",
    "    \"\"\"\n",
    "    y = o.astype(np.uint8)\n",
    "    resized = scipy.misc.imresize(y, image_size) # (80,80,3)\n",
    "    # return np.expand_dims(resized.astype(np.float32),axis=2)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 160)\n",
      "(80, 80)\n",
      "(1, 80, 80)\n"
     ]
    }
   ],
   "source": [
    "data = 0.2126 * data[:, :, 0] + 0.7152 * data[:, :, 1] + 0.0722 * data[:, :, 2]\n",
    "print(data.shape)\n",
    "resized = cv2.resize(data, dsize=(80, 80), interpolation=cv2.INTER_CUBIC)\n",
    "print(resized.shape)\n",
    "resized = np.expand_dims(resized,axis=0)\n",
    "print(resized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 80, 1)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    data, _, _, _ = env.step(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 80)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data = env.reset()\n",
    "# data = prepro(data)\n",
    "data = 0.2126 * data[:, :, 0] + 0.7152 * data[:, :, 1] + 0.0722 * data[:, :, 2]\n",
    "data = data[30:,:]\n",
    "resized = cv2.resize(data, dsize=(80, 80), interpolation=cv2.INTER_CUBIC)\n",
    "print(resized.shape)\n",
    "plt.gray()\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(resized, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = torch.nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3)\n",
    "conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Variable(torch.Tensor(np.expand_dims(resized,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 78, 78])\n",
      "torch.Size([1, 32, 76, 76])\n"
     ]
    }
   ],
   "source": [
    "x = conv1(img)\n",
    "print(x.shape)\n",
    "y = conv2(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(torch.nn.Module):\n",
    "    def __init__(self, gamma=0.99, lr=1e-4, rmsprop_decay=0.99):\n",
    "        super(Policy, self).__init__()\n",
    "\n",
    "#         self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3) # (batch_size, 16, 208, 158)\n",
    "#         self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3) # (batch_size, 32, 206, 156)\n",
    "#         self.fc1 = torch.nn.Linear(32 * 76 * 76, 64)\n",
    "#         self.fc2 = torch.nn.Linear(64, 32)\n",
    "#         self.fc3 = torch.nn.Linear(32, 3) # 6 actions to choose from, only taking 3 here\n",
    "#         # known actions: 0(no move), 2(up), 3(down)\n",
    "\n",
    "        self.fc4 = torch.nn.Linear(80*80, 256)\n",
    "        self.fc5 = torch.nn.Linear(256, 256)\n",
    "        self.fc6 = torch.nn.Linear(256, 3)\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.lr = lr\n",
    "        self.rmsprop_decay = rmsprop_decay\n",
    "        self.random_action_episodes = 0\n",
    "        \n",
    "        self.output2action = {0: 0, 1: 2, 2: 3}\n",
    "        self.saved_log_probs = []\n",
    "        self.rewards = []\n",
    "        \n",
    "    def forward(self, x): # x: np.array (1, 80, 80)\n",
    "\n",
    "        x = Variable(torch.Tensor(x))\n",
    "        if torch.cuda.is_available():\n",
    "             x = x.cuda()\n",
    "        x = x.view(-1, 80*80)\n",
    "        x = self.fc4(x) # TODO: add batch norm?\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.fc5(x)\n",
    "        x = torch.nn.functional.selu(x)\n",
    "        x = self.fc6(x)\n",
    "\n",
    "\n",
    "        action_probs = torch.nn.functional.softmax(x, dim=1)\n",
    "        return action_probs # (batch_size, 6)\n",
    "\n",
    "    def reset(self):\n",
    "        self.saved_log_probs = []\n",
    "        self.rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = Policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-1.1680e-02  6.4054e-03 -6.8477e-03  ...   6.1079e-03 -7.7141e-04 -1.0044e-02\n",
       "-6.8361e-03  4.1599e-03 -3.1595e-05  ...   8.4786e-03  4.3608e-03 -1.0854e-02\n",
       "-4.2969e-03  6.0781e-03 -8.1219e-03  ...  -1.2140e-02  2.4697e-03  4.5803e-03\n",
       "                ...                   ⋱                   ...                \n",
       " 9.7562e-03  1.6991e-03 -1.1516e-02  ...   1.2231e-02 -1.0155e-02 -7.4317e-03\n",
       "-3.2122e-03 -7.0174e-03 -7.9087e-03  ...  -5.9183e-03 -5.6066e-03  1.1751e-02\n",
       "-5.3492e-03 -1.1511e-02  2.9818e-03  ...   6.0135e-03 -2.9464e-03  8.7818e-03\n",
       "[torch.FloatTensor of size 256x6400]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.state_dict()['fc4.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-205-13f0e060ec14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fc4.weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "policy.named_parameters()['fc4.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      " 3.1583e-03 -2.6997e-02  3.0856e-02  ...   2.0772e-02 -3.2540e-02 -1.8699e-02\n",
      "-3.9914e-02 -3.2156e-02 -3.5675e-03  ...   5.8396e-02  2.1690e-02 -9.8056e-03\n",
      " 3.0208e-02 -1.8891e-02  6.0833e-02  ...  -2.6416e-02  5.5039e-02  4.5472e-02\n",
      "                ...                   ⋱                   ...                \n",
      " 3.1977e-02  1.9102e-02  4.9685e-02  ...  -8.4944e-03 -5.4329e-02  1.5440e-02\n",
      " 4.2826e-02 -3.2541e-02 -5.9553e-02  ...   2.7837e-02  3.7150e-02 -5.2498e-02\n",
      " 2.9265e-02  7.7444e-03 -3.7267e-02  ...  -3.1599e-02 -2.9033e-02  5.6836e-02\n",
      "[torch.FloatTensor of size 256x256]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, param in enumerate(policy.parameters()):\n",
    "    if idx == 2:\n",
    "        print(param)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for param in policy.parameters():\n",
    "    print(param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4fd5410833e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# print('[Time step {}] Finished step, about to backprop'.format(t))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mpolicy_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# NOTE: only tried this with batch_size=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                                             \u001b[0;31m#if batch_size > 1, not sure if we need to manually average gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "policy = Policy()\n",
    "policy.train()\n",
    "optimizer = torch.optim.Adam(policy.parameters())\n",
    "for i_episode in range(20):\n",
    "    observation = env.reset()\n",
    "    optimizer.zero_grad()\n",
    "    policy.episode_reward = 0\n",
    "     \n",
    "    for t in range(100):\n",
    "        # self.env.env.render()\n",
    "        policy_output = policy(observation) # (batch_size, 6)\n",
    "        action = int(torch.max(policy_output, dim=1)[1].data) # torch.max returns (max val, argmax)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        policy.episode_reward += reward\n",
    "        # print('[Time step {}] Finished step, about to backprop'.format(t))\n",
    "        policy_output[:,action].backward(retain_graph=False) # NOTE: only tried this with batch_size=1\n",
    "                                            #if batch_size > 1, not sure if we need to manually average gradients\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "    if not done:\n",
    "        print('Force terminated episode after running for 100 steps')\n",
    "    print('[After {} seconds] Reward is {}'.format(time.time()-a, policy.episode_reward))\n",
    "    \n",
    "    for param in policy.parameters():\n",
    "        param.grad *= policy.episode_reward\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = torch.nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3)\n",
    "conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n",
    "fc1 = torch.nn.Linear(206 * 156 * 32, 512)\n",
    "fc2 = torch.nn.Linear(512,6)\n",
    "logsoftmax = torch.nn.LogSoftmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-20bff870d3f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m210\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "img = Variable(torch.Tensor(a.reshape(1,3,210,160)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 208, 158])\n",
      "torch.Size([1, 32, 206, 156])\n"
     ]
    }
   ],
   "source": [
    "x = conv1(img)\n",
    "print(x.shape)\n",
    "y = conv2(x)\n",
    "print(y.shape)\n",
    "y = y.view(-1, 32*206*156)\n",
    "z = fc1(y)\n",
    "z = fc2(z)\n",
    "output = logsoftmax(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "  8.2107   4.8800  -6.4096  -6.6704  13.4930   6.7540\n",
       "[torch.FloatTensor of size 1x6]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = int(torch.max(z, dim=1)[1].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[:,action].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1 = torch.nn.Linear(16, 8)\n",
    "fc2 = torch.nn.Linear(8,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(torch.Tensor([[i for i in range(16)]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = fc1(x)\n",
    "y = fc2(y)\n",
    "y = torch.nn.functional.softmax(y, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.0997  0.9003\n",
       "[torch.FloatTensor of size 1x2]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_sampler = torch.distributions.Categorical(y[0])\n",
    "log_prob = action_sampler.log_prob(action_sampler.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "\n",
      "Columns 0 to 12 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 15 \n",
      "    0     0     0\n",
      "    0     0     0\n",
      "    0     0     0\n",
      "    0     0     0\n",
      "    0     0     0\n",
      "    0     0     0\n",
      "    0     0     0\n",
      "    0     0     0\n",
      "[torch.FloatTensor of size 8x16]\n",
      "\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 8]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for param in fc1.parameters():\n",
    "    print(param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "(log_prob * 2).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "\n",
      "Columns 0 to 9 \n",
      " 0.0000 -0.0222 -0.0444 -0.0665 -0.0887 -0.1109 -0.1331 -0.1553 -0.1774 -0.1996\n",
      " 0.0000  0.0242  0.0485  0.0727  0.0970  0.1212  0.1454  0.1697  0.1939  0.2181\n",
      " 0.0000 -0.1092 -0.2185 -0.3277 -0.4370 -0.5462 -0.6554 -0.7647 -0.8739 -0.9832\n",
      " 0.0000 -0.1141 -0.2281 -0.3422 -0.4562 -0.5703 -0.6843 -0.7984 -0.9125 -1.0265\n",
      " 0.0000  0.0941  0.1881  0.2822  0.3763  0.4703  0.5644  0.6585  0.7525  0.8466\n",
      " 0.0000 -0.0893 -0.1787 -0.2680 -0.3573 -0.4466 -0.5360 -0.6253 -0.7146 -0.8039\n",
      " 0.0000 -0.1265 -0.2529 -0.3794 -0.5059 -0.6324 -0.7588 -0.8853 -1.0118 -1.1382\n",
      " 0.0000  0.1025  0.2049  0.3074  0.4099  0.5124  0.6148  0.7173  0.8198  0.9223\n",
      "\n",
      "Columns 10 to 15 \n",
      "-0.2218 -0.2440 -0.2662 -0.2883 -0.3105 -0.3327\n",
      " 0.2424  0.2666  0.2909  0.3151  0.3393  0.3636\n",
      "-1.0924 -1.2016 -1.3109 -1.4201 -1.5293 -1.6386\n",
      "-1.1406 -1.2546 -1.3687 -1.4827 -1.5968 -1.7109\n",
      " 0.9407  1.0347  1.1288  1.2229  1.3169  1.4110\n",
      "-0.8933 -0.9826 -1.0719 -1.1612 -1.2506 -1.3399\n",
      "-1.2647 -1.3912 -1.5177 -1.6441 -1.7706 -1.8971\n",
      " 1.0247  1.1272  1.2297  1.3322  1.4346  1.5371\n",
      "[torch.FloatTensor of size 8x16]\n",
      "\n",
      "Variable containing:\n",
      "-0.0222\n",
      " 0.0242\n",
      "-0.1092\n",
      "-0.1141\n",
      " 0.0941\n",
      "-0.0893\n",
      "-0.1265\n",
      " 0.1025\n",
      "[torch.FloatTensor of size 8]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for param in fc1.parameters():\n",
    "    print(param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "\n",
      "Columns 0 to 12 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 15 \n",
      "    0     0     0\n",
      "    0     0     0\n",
      "    0     0     0\n",
      "    0     0     0\n",
      "    0     0     0\n",
      "    0     0     0\n",
      "    0     0     0\n",
      "    0     0     0\n",
      "[torch.FloatTensor of size 8x16]\n",
      "\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 8]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for param in fc1.parameters():\n",
    "    print(param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "next expected at least 1 arguments, got 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-fa1952f122d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: next expected at least 1 arguments, got 0"
     ]
    }
   ],
   "source": [
    "for a in range(5):\n",
    "    next()\n",
    "    print(a)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
